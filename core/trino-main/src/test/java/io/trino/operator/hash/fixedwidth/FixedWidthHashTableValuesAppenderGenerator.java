/*
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package io.trino.operator.hash.fixedwidth;

import com.squareup.javapoet.JavaFile;
import com.squareup.javapoet.MethodSpec;
import com.squareup.javapoet.TypeSpec;
import io.trino.operator.hash.AbstractHashTableValuesAppender;
import io.trino.operator.hash.ColumnValueExtractor;
import io.trino.operator.hash.HashTableData;
import io.trino.operator.hash.fastbb.FastByteBuffer;
import io.trino.spi.PageBuilder;
import io.trino.spi.block.BlockBuilder;

import java.io.IOException;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.util.Objects;

import static java.lang.String.format;
import static javax.lang.model.element.Modifier.FINAL;
import static javax.lang.model.element.Modifier.PRIVATE;
import static javax.lang.model.element.Modifier.PROTECTED;
import static javax.lang.model.element.Modifier.PUBLIC;

/**
 * This class can be used to generate FixedWidthHashTableValuesAppenderXChannels classes.
 * This is a one time generation not invoked during build time.
 * In order to generate new version of classes:
 * <ul>
 * <li>Run main method of this class</li>
 * <li>Add license header to created classes (unsupported in Java poet)</li>
 * <li>Format/optimize imports</li>
 * </ul>
 * The class is placed in the test code to prevent unnecessary dependencies in main.
 */
public class FixedWidthHashTableValuesAppenderGenerator
{
    public static final String MODULE_NAME = "core/trino-main";
    public static final Package PACKAGE = GenericFixedWidthHashTableValuesAppender.class.getPackage();
    public static final String CLASS_COMMENT = "This class has been generated by the FixedWidthHashTableValuesAppenderGenerator class.\n" +
            "The generation is a one-time event and is not repeated during build";

    private FixedWidthHashTableValuesAppenderGenerator() {}

    public static void generate(int numberOfChannels)
            throws IOException
    {
        String className = "FixedWidthHashTableValuesAppender" + numberOfChannels + "Channels";
        TypeSpec.Builder mainClass = TypeSpec.classBuilder(className)
                .superclass(AbstractHashTableValuesAppender.class)
                .addJavadoc(CLASS_COMMENT)
                .addModifiers(PUBLIC, FINAL);

        for (int i = 0; i < numberOfChannels; i++) {
            mainClass.addField(ColumnValueExtractor.class, "columnValueExtractor" + i, PRIVATE, FINAL);
        }

        // we are starting at 1 as we know the value0Offset is always 0
        for (int i = 1; i < numberOfChannels; i++) {
            mainClass.addField(int.class, format("value%dOffset", i), PRIVATE, FINAL);
        }

        mainClass.addMethod(constructor(numberOfChannels));
        mainClass.addMethod(appendValuesToBatch(numberOfChannels));
        for (int i = 0; i < numberOfChannels; i++) {
            mainClass.addMethod(appendValueBatch(i));
        }
        mainClass.addMethod(appendValuesTo(numberOfChannels));
        for (int i = 0; i < numberOfChannels; i++) {
            mainClass.addMethod(appendValue(i));
        }

        JavaFile javaFile = JavaFile.builder(PACKAGE.getName() + ".gen", mainClass.build())
                .indent("    ")
                .addStaticImport(Objects.class, "requireNonNull")
                .addStaticImport(com.google.common.base.Preconditions.class, "checkArgument")
                .addStaticImport(io.trino.spi.type.BigintType.class, "BIGINT")
                .build();

        javaFile.writeTo(getSrcDir());
        System.out.printf("generated %s to %s\n", className, getSrcDir());
    }

    private static MethodSpec constructor(int numberOfChannels)
    {
        MethodSpec.Builder constructor = MethodSpec.constructorBuilder()
                .addModifiers(PUBLIC)
                .addParameter(FixedWidthEntryStructure.class, "structure");

        constructor.addStatement("requireNonNull(structure, \"structure is null\")");
        constructor.addStatement("checkArgument(structure.getHashChannelsCount() == $1L)", numberOfChannels);

        for (int i = 0; i < numberOfChannels; i++) {
            constructor.addStatement("columnValueExtractor$1L = structure.getColumnValueExtractors()[$1L]", i);
        }

        for (int i = 1; i < numberOfChannels; i++) {
            constructor.addStatement("value$1LOffset = structure.getValuesOffsets()[$1L]", i);
        }

        return constructor
                .build();
    }

    private static MethodSpec appendValuesToBatch(int numberOfChannels)
    {
        MethodSpec.Builder method = MethodSpec.methodBuilder("appendValuesTo")
                .addModifiers(PROTECTED)
                .addAnnotation(Override.class)
                .addParameter(HashTableData.class, "data")
                .addParameter(int.class, "batchSize")
                .addParameter(int[].class, "groupIdBatch")
                .addParameter(int[].class, "positionsBatch")
                .addParameter(int[].class, "valuesOffsetBatch")
                .addParameter(boolean[].class, "isNullBatch")
                .addParameter(PageBuilder.class, "pageBuilder")
                .addParameter(int.class, "outputChannelOffset")
                .addParameter(boolean.class, "outputHash");

        method.addStatement("FixedWidthGroupByHashTableEntries entries = (FixedWidthGroupByHashTableEntries) data.entries()");
        method.beginControlFlow("for (int i = 0; i < batchSize; i++)");
        method.addStatement("positionsBatch[i] = data.getPosition(groupIdBatch[i])");
        method.endControlFlow();

        method.beginControlFlow("for (int i = 0; i < batchSize; i++)");
        method.addStatement("valuesOffsetBatch[i] = entries.getValuesOffset(positionsBatch[i])");
        method.endControlFlow();

        method.addStatement("FastByteBuffer buffer = entries.getBuffer()");

        for (int i = 0; i < numberOfChannels; i++) {
            method.addStatement("appendValue$1L(pageBuilder, outputChannelOffset, entries, batchSize, positionsBatch, valuesOffsetBatch, isNullBatch, buffer)", i);
        }

        method.beginControlFlow("if (outputHash)");
        method.addStatement("$2T hashBlockBuilder = pageBuilder.getBlockBuilder(outputChannelOffset + $1L)", numberOfChannels, BlockBuilder.class);
        method.beginControlFlow("for (int i = 0; i < batchSize; i++)");
        method.addStatement("BIGINT.writeLong(hashBlockBuilder, entries.getHash(positionsBatch[i]))");
        method.endControlFlow();
        method.endControlFlow();

        return method.build();
    }

    private static MethodSpec appendValueBatch(int channel)
    {
        MethodSpec.Builder method = MethodSpec.methodBuilder("appendValue" + channel)
                .addModifiers(PRIVATE)
                .addParameter(PageBuilder.class, "pageBuilder")
                .addParameter(int.class, "outputChannelOffset")
                .addParameter(FixedWidthGroupByHashTableEntries.class, "entries")
                .addParameter(int.class, "batchSize")
                .addParameter(int[].class, "positionsBatch")
                .addParameter(int[].class, "valuesOffsetBatch")
                .addParameter(boolean[].class, "isNullBatch")
                .addParameter(FastByteBuffer.class, "buffer");

        method.beginControlFlow("for (int i = 0; i < batchSize; i++)");
        method.addStatement("isNullBatch[i] = entries.isNull(positionsBatch[i], $1L) == 1", channel);
        method.endControlFlow();

        if (channel == 0) {
            method.addStatement("BlockBuilder blockBuilder$1L = pageBuilder.getBlockBuilder(outputChannelOffset)", channel);
        }
        else {
            method.addStatement("BlockBuilder blockBuilder$1L = pageBuilder.getBlockBuilder(outputChannelOffset + $1L)", channel);
        }
        method.beginControlFlow("for (int i = 0; i < batchSize; i++)");
        method.beginControlFlow("if (isNullBatch[i])");
        method.addStatement("blockBuilder$1L.appendNull()", channel);
        method.nextControlFlow("else");
        if (channel == 0) {
            method.addStatement("columnValueExtractor$1L.appendValue(buffer, valuesOffsetBatch[i], blockBuilder$1L)", channel);
        }
        else {
            method.addStatement("columnValueExtractor$1L.appendValue(buffer, valuesOffsetBatch[i] + value$1LOffset, blockBuilder$1L)", channel);
        }
        method.endControlFlow();
        method.endControlFlow();

        return method.build();
    }

    private static MethodSpec appendValuesTo(int numberOfChannels)
    {
        MethodSpec.Builder method = MethodSpec.methodBuilder("appendValuesTo")
                .addModifiers(PUBLIC)
                .addAnnotation(Override.class)
                .addParameter(HashTableData.class, "data")
                .addParameter(int.class, "groupId")
                .addParameter(PageBuilder.class, "pageBuilder")
                .addParameter(int.class, "outputChannelOffset")
                .addParameter(boolean.class, "outputHash");

        method.addStatement("FixedWidthGroupByHashTableEntries entries = (FixedWidthGroupByHashTableEntries) data.entries()");
        method.addStatement("int position = data.getPosition(groupId)");
        method.addStatement("FastByteBuffer buffer = entries.getBuffer()");
        method.addStatement("int valuesOffset = entries.getValuesOffset(position)");

        for (int i = 0; i < numberOfChannels; i++) {
            method.addStatement("appendValue$1L(pageBuilder, outputChannelOffset, entries, position, valuesOffset, buffer)", i);
        }

        method.beginControlFlow("if (outputHash)");
        method.addStatement("$2T hashBlockBuilder = pageBuilder.getBlockBuilder(outputChannelOffset + $1L)", numberOfChannels, BlockBuilder.class);
        method.addStatement("BIGINT.writeLong(hashBlockBuilder, entries.getHash(position))");
        method.endControlFlow();

        return method.build();
    }

    private static MethodSpec appendValue(int channel)
    {
        MethodSpec.Builder method = MethodSpec.methodBuilder("appendValue" + channel)
                .addModifiers(PRIVATE)
                .addParameter(PageBuilder.class, "pageBuilder")
                .addParameter(int.class, "outputChannelOffset")
                .addParameter(FixedWidthGroupByHashTableEntries.class, "entries")
                .addParameter(int.class, "position")
                .addParameter(int.class, "valuesOffset")
                .addParameter(FastByteBuffer.class, "buffer");

        if (channel == 0) {
            method.addStatement("BlockBuilder blockBuilder$1L = pageBuilder.getBlockBuilder(outputChannelOffset)", channel);
        }
        else {
            method.addStatement("BlockBuilder blockBuilder$1L = pageBuilder.getBlockBuilder(outputChannelOffset + $1L)", channel);
        }
        method.beginControlFlow("if (entries.isNull(position, $1L) == 1)", channel);
        method.addStatement("blockBuilder$1L.appendNull()", channel);
        method.nextControlFlow("else");
        if (channel == 0) {
            method.addStatement("columnValueExtractor$1L.appendValue(buffer, valuesOffset, blockBuilder$1L)", channel);
        }
        else {
            method.addStatement("columnValueExtractor$1L.appendValue(buffer, valuesOffset + value$1LOffset, blockBuilder$1L)", channel);
        }
        method.endControlFlow();

        return method.build();
    }

    private static Path getSrcDir()
    {
        return Paths.get(MODULE_NAME)
                .resolve("src")
                .resolve("main")
                .resolve("java");
    }

    public static void main(String[] args)
            throws IOException
    {
        for (int i = 1; i <= 20; i++) {
            generate(i);
        }
    }
}
